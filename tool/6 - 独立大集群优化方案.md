# kube-apiserver参数优化

kube-apiserver默认max-requests-inflight是400，max-mutating-requests-inflight默认200，当读写请求超过此值时会返回429，Too Many Request错误, --event-ttl 默认为1h,  当集群event较多时会导致集群性能恶化，建议在控制台开启event持久化将此值尽量调低, 针对大集群建议做如下优化.

| 节点数(N) | 参数名 | 值 |
| --- | --- | --- |
| 1000 < N < 3000 | max-requests-inflight | 1500
| 1000 < N < 3000 | max-mutating-requests-inflight | 500
| N >= 3000 | max-requests-inflight | 3000
| N >= 3000 | max-mutating-requests-inflight | 1000
| 任何节点 | event-ttl | 10m以内


修改方法如下:
1. 独立集群kube-apiserver/etcd/kube-controller-manager/kube-scheduler组件全部通过static pod部署, 登录MASTER机器，进入yml文件目录/etcd/kubernetes/manifests,查看当前目录下是否有如下的YAML文件,然后备份此目录文件到其他目录.
2. 修改kube-apiserver.yaml文件，添加以上参数,保存退出.
3. kubelet会实时监听yml文件变更，然后删除旧POD，创建新POD，可以通过docker ps或者kubectl get pod/apiserver-master-ip -n kube-system命令查看kube-apiserver是否重建成功，若未有apiserver容器，docker ps -a命令查看退出的容器ID，通过docker logs container_id查看退出原因, 若apiserver一直未重建，可以尝试重启kubelet。
4. 启动成功后，本机验证kubectl get node是否正常，如正常则分别对剩余两台MASTER进行变更操作。
5. 如异常影响业务了，建议先回滚，把备份yml文件拷贝到/etc/kubernetes/manifests目录。


# kube-controller-manager参数优化

kube-controller-manager默认kube-api-qps默认20，--kube-api-burst默认30，此参数设置过小会导致调度缓慢等，针对大集群建议做如下优化.

| 节点数(N) | 参数名 | 值
| --- | --- | --- |
| 1000 < N < 3000 | kube-api-qps | 400
| 1000 < N < 3000 | kube-api-burst | 600
| N >= 3000 | kube-api-qps | 800
| N >= 3000 | kube-api-burst | 1000

> 修改方法参考kube-apiserver.

# kube-scheduler参数优化

kube-scheduler默认kube-api-qps默认50，--kube-api-burst默认100，此参数设置过小会导致调度缓慢等，针对大集群建议做如下优化.
| 节点数(N) | 参数名 | 值
| --- | --- | --- |
| 1000 < N < 3000 | kube-api-qps | 400
| 1000 < N < 3000 | kube-api-burst | 600
| N >= 3000 | kube-api-qps | 600
| N >= 3000 | kube-api-burst | 800

> 修改方法参考kube-apiserver.

# etcd参数优化

etcd默认quota-backend-bytes默认为2G，当db大小达到此值时会导致不可写，heartbeat-interval 默认100ms,election-timeout默认为500ms, 此参数设置过小会导致集群负载增高时，etcd集群发生Leader选举，导致集群不稳定,针对大集群建议做如下优化.

| 参数名 | 值
| --- | ---
| quota-backend-bytes | 6442450944
| heartbeat-interval | 500
| election-timeout | 1500

## etcd event独立

独立集群默认event未独立，当集群频繁大量创建POD、或者POD处于异常状态频繁等导致频繁上报事件时会大量写压垮ETCD，导致db满, 因此需要将EVENT从主ETCD独立出去。

基于开源的etcd-operator部署集群
容器化部署，基于RAW POD + CRD
部署快但集群稳定性未经大规模验证，三个POD中任意两个故障会导致EVENT数据丢失，需人工介入才能恢复集群

## k8s event限速

通过Admission Controller的EventRateLimiter对event进行进行限速. alpha特性，如已独立不建议使用.
https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/

# Kubelet配置

* 设置 --serialize-image-pulls=false
该选项配置串行拉取镜像，默认值时true，配置为false可以增加并发度。但是如果docker daemon
版本小于 1.9，且使用 aufs 存储则不能改动该选项。
* 设置 --image-pull-progress-deadline=30
配置镜像拉取超时。默认值时1分，对于大镜像拉取需要适量增大超时时间。
* Kubelet 单节点允许运行的最大 Pod 数：--max-pods=110（默认是 110，可以根据实际需要设置）


# Docker 配置

* 设置 max-concurrent-downloads=10
配置每个pull操作的最大并行下载数，提高镜像拉取效率，默认值是3。
* 使用 SSD 存储。
* 预加载 pause 镜像，启动pod时都会拉取pause镜像，为了减小拉取pause镜像网络带宽，可以每个node预加载pause镜像。
* log-driver配置：Log driver是Docker用来接收来自容器内部stdout/stderr的日志的模块，Docker默认的log driver是JSON File logging driver。这里只讲json-file的配置，其他的请查阅相关文档。json-file会将容器日志存储在docker host machine的/var/lib/docker/containers/<container id>/<container id>-json.log（需要root权限才能够读），既然日志是存在磁盘上的，那么就要磁盘消耗的问题。下面介绍两个关键参数：
   * max-size，单个日志文件最大尺寸，当日志文件超过此尺寸时会滚动，即不再往这个文件里写，而是写到一个新的文件里。默认值是-1，代表无限。
   * max-files，最多保留多少个日志文件。默认值是1。
    ```
    {
        "log-driver": "json-file",
        "log-opts": {
            "max-size": "100m",
            "max-files":"5"
        }
    }
    ```

* storage-driver:Docker推荐使用overlay2作为Storage driver。
  ```
    {
        "storage-driver": "overlay2"
    }
  ```
* bridge网络的mtu:如果docker host machine的网卡MTU为1500，则不需要此步骤.MTU是一个很容易被忽略的参数，Docker默认的MTU是1500，这也是大多数网卡的MTU值。但是在虚拟化环境下，docker host machine网卡的MTU可能不是1500，比如在openstack创建的虚拟的网卡的MTU是1450,可以通过ip link查看主机的mtu：
  ```
   $ ip link
    1: ens3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000
    link/ether fa:16:3e:71:09:f5 brd ff:ff:ff:ff:ff:ff
  ```
  也可以通过下列命令观察bridge网络的MTU：
  ```
     docker network inspect -f '{{json .Options}}' bridge   
  ```
  当Docker网络的MTU比docker host machine网卡MTU大的时候可能会发生：
  * 容器外出通信失败
  * 影响网络性能
 所以将Docker网络MTU设置成和host machine网卡保持一致就行了，比如：
 ```
 {
  "mtu": 1450
 }
 ```
* bridge网络的子网:观察默认bridge的子网是否与已有网络冲突.
```
$ docker network inspect -f '{{json .IPAM}}' bridge

{"Driver":"default","Options":null,"Config":[{"Subnet":"172.17.0.0/16","Gateway":"172.17.0.1"}]}
```
如果有则参考[Configure the default bridge network](https://docs.docker.com/network/bridge/#configure-the-default-bridge-network)（可忽略IPv6部分的配置）。
* 开启live restore特性能够在Docker daemon停止的时候依旧让容器保持运行。注意：在Daemon停机期间，容器的日志被暂存在一个缓冲区中，如果缓冲区满了（默认大小64K），则容器就会被阻塞住。

```
{
  "live-restore": true
}
```

* 当前用户添加到docker用户组
  ```
    sudo usermod -aG docker $USER
  ```
* registry-mirrors 添加镜像加速器
* Docker内置了一个DNS Server，它用来做两件事情：解析docker network里的容器或Service的IP地址；把解析不了的交给外部DNS Server解析（dns参数设定的地址),默认情况下，dns参数值为Google DNS nameserver：8.8.8.8和8.8.4.4。可以改成公司内部的。


# 内核配置
增大内核选项配置 /etc/sysctl.conf：

* max-file 表示系统级别的能够打开的文件句柄的数量， 一般如果遇到文件句柄达到上限时，会碰到
"Too many open files"或者Socket/File: Can’t open so many files等错误。fs.file-max=1000000

* 配置arp cache 大小: net.ipv4.neigh.default.gc_thresh1=1024,存在于ARP高速缓存中的最少层数，如果少于这个数，垃圾收集器将不会运行。缺省值是128.
* net.ipv4.neigh.default.gc_thresh2=4096,保存在 ARP 高速缓存中的最多的记录软限制。垃圾收集器在开始收集前，允许记录数超过这个数字 5 秒。缺省值是 512。
* net.ipv4.neigh.default.gc_thresh3=8192,保存在 ARP 高速缓存中的最多记录的硬限制，一旦高速缓存中的数目高于此，垃圾收集器将马上运行。缺省值是1024。
以上三个参数，当内核维护的arp表过于庞大时候，可以考虑优化


* net.netfilter.nf_conntrack_max=10485760,允许的最大跟踪连接条目，是在内核内存中netfilter可以同时处理的“任务”（连接跟踪条目）

* 哈希表大小（只读）（64位系统、8G内存默认 65536，16G翻倍，如此类推）net.netfilter.nf_conntrack_tcp_timeout_established=300,net.netfilter.nf_conntrack_buckets=655360

* net.core.netdev_max_backlog=10000每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。
关于conntrack的详细说明：https://testerhome.com/topics/7509


* fs.inotify.max_user_instances=524288 默认值: 128 指定了每一个real user ID可创建的inotify instatnces的数量上限


* fs.inotify.max_user_watches=524288 默认值: 8192 指定了每个inotify instance相关联的watches的上限